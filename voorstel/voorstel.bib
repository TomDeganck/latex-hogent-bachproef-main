@inbook{Cooper2011,
	title        = {Sign Language Recognition},
	author       = {Cooper, Helen and Holt, Brian and Bowden, Richard},
	year         = 2011,
	booktitle    = {Visual Analysis of Humans: Looking at People},
	publisher    = {Springer London},
	address      = {London},
	pages        = {539--562},
	doi          = {10.1007/978-0-85729-997-0_27},
	isbn         = {978-0-85729-997-0},
	url          = {https://doi.org/10.1007/978-0-85729-997-0_27},
	editor       = {Moeslund, Thomas B., Hilton, Adrian, Kr{\"u}ger, Volker, and Sigal, Leonid},
	abstract     = {This chapter covers the key aspects of sign-language recognition (SLR), starting with a brief introduction to the motivations and requirements, followed by a pr{\'e}cis of sign linguistics and their impact on the field. The types of data available and the relative merits are explored allowing examination of the features which can be extracted. Classifying the manual aspects of sign (similar to gestures) is then discussed from a tracking and non-tracking viewpoint before summarising some of the approaches to the non-manual aspects of sign languages. Methods for combining the sign classification results into full SLR are given showing the progression towards speech recognition techniques and the further adaptations required for the sign specific case. Finally the current frontiers are discussed and the recent research presented. This covers the task of continuous sign recognition, the work towards true signer independence, how to effectively combine the different modalities of sign, making use of the current linguistic research and adapting to larger more noisy data sets.},
	timestamp    = {2024-10-29}
}
@article{10.56726/irjmets32712,
	title        = {Real time sign language recognition using computer vision},
	year         = 2023,
	journal      = {International Research Journal of Modernization in Engineering Technology and Science},
	doi          = {10.56726/irjmets32712},
	timestamp    = {2024-11-04}
}
@article{10.1093/ijl/ecy008,
	title        = {Looking back while moving forward: the impact of societal and technological developments on flemish sign language lexicographic practices},
	author       = {Vermeerbergen, M. and Herreweghe, M.},
	year         = 2018,
	journal      = {International Journal of Lexicography},
	volume       = 31,
	pages        = {167--195},
	doi          = {10.1093/ijl/ecy008},
	issue        = 2,
	timestamp    = {2024-11-04}
}
@article{10.1109/iccv.2019.00550,
	title        = {Fingerspelling recognition in the wild with iterative visual attention},
	author       = {Shi, B. and Rio, A. and Keane, J. and Brentari, D. and Shakhnarovich, G. and Livescu, K.},
	year         = 2019,
	doi          = {10.1109/iccv.2019.00550},
	timestamp    = {2024-11-04}
}
@article{10.11591/csit.v3i3.p186-193,
	title        = {Pakistan sign language to urdu translator using kinect},
	author       = {Ahmed, S. and Shafiq, H. and Raheel, Y. and Chishti, N. and Asad, S.},
	year         = 2022,
	journal      = {Computer Science and Information Technologies},
	volume       = 3,
	pages        = {186--193},
	doi          = {10.11591/csit.v3i3.p186-193},
	issue        = 3,
	timestamp    = {2024-11-04}
}
@article{10.48550/arxiv.2012.15840,
	title        = {Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
	author       = {Zheng, S. and Lu, J. and Zhao, H. and Zhu, X. and Luo, Z. and Wang, Y. and Fu, Y. and Feng, J. and Xiang, T. and Torr, P. and Zhang, L.},
	year         = 2020,
	doi          = {10.48550/arxiv.2012.15840},
	timestamp    = {2024-11-04}
}
@article{10.57197/jdr-2023-0047,
	title        = {Sign language recognition using artificial rabbits optimizer with siamese neural network for persons with disabilities},
	author       = {Marzouk, R.},
	year         = 2023,
	volume       = 2,
	doi          = {10.57197/jdr-2023-0047},
	issue        = 4,
	timestamp    = {2024-11-04}
}
@article{10.22214/ijraset.2023.52628,
	title        = {Ai-based sign language recognition system for deaf and hard-of-hearing individuals},
	author       = {Gade, P.},
	year         = 2023,
	journal      = {International Journal for Research in Applied Science and Engineering Technology},
	volume       = 11,
	pages        = {4472--4476},
	doi          = {10.22214/ijraset.2023.52628},
	issue        = 5,
	timestamp    = {2024-11-04}
}
@article{10.1109/wacv45572.2020.9093512,
	title        = {Word-level deep sign language recognition from video: a new large-scale dataset and methods comparison},
	author       = {Li, D. and Opazo, C. and Yu, X. and Li, H.},
	year         = 2020,
	pages        = {1448--1458},
	doi          = {10.1109/wacv45572.2020.9093512},
	timestamp    = {2024-11-04}
}
@article{10.18178/ijmlc.2019.9.6.879,
	title        = {Static sign language recognition using deep learning},
	author       = {Tolentino, L. and Juan, R. and Thio-ac, A. and Pamahoy, M. and Forteza, J. and Garcia, X.},
	year         = 2019,
	journal      = {International Journal of Machine Learning and Computing},
	volume       = 9,
	pages        = {821--827},
	doi          = {10.18178/ijmlc.2019.9.6.879},
	issue        = 6,
	timestamp    = {2024-11-04}
}
@article{10.24003/emitter.v9i1.613,
	title        = {Indian sign language recognition through hybrid convnet-lstm networks},
	author       = {H, M.},
	year         = 2021,
	journal      = {Emitter International Journal of Engineering Technology},
	volume       = 9,
	pages        = {182--203},
	doi          = {10.24003/emitter.v9i1.613},
	issue        = 1,
	timestamp    = {2024-11-04}
}
@article{10.18653/v1/2020.conll-1.51,
	title        = {A dataset for linguistic understanding, visual evaluation, and recognition of sign languages: the k-rsl},
	author       = {Imashev, A. and Mukushev, M. and Kimmelman, V. and Sandygulova, A.},
	year         = 2020,
	doi          = {10.18653/v1/2020.conll-1.51},
	timestamp    = {2024-11-04}
}
@article{10.1049/iet-cvi.2017.0598,
	title        = {Multi-modality-based arabic sign language recognition},
	author       = {Elpeltagy, M. and Abdelwahab, M. and Hussein, M. and Shoukry, A. and Shoala, A. and Galal, M.},
	year         = 2018,
	journal      = {Iet Computer Vision},
	volume       = 12,
	pages        = {1031--1039},
	doi          = {10.1049/iet-cvi.2017.0598},
	issue        = 7,
	timestamp    = {2024-11-04}
}
@article{10.1109/ictas.2019.8703631,
	title        = {Video relay service for deaf people using webrtc},
	author       = {Henney, A. and Tucker, W.},
	year         = 2019,
	pages        = {1--6},
	doi          = {10.1109/ictas.2019.8703631},
	timestamp    = {2024-11-04}
}
@article{10.22214/ijraset.2022.46470,
	title        = {A survey on real time sign language detector using ml},
	author       = {Gattani, P. and Laddha, S. and Srivastava, S. and BM, V.},
	year         = 2022,
	journal      = {International Journal for Research in Applied Science and Engineering Technology},
	volume       = 10,
	pages        = {1635--1643},
	doi          = {10.22214/ijraset.2022.46470},
	issue        = 8,
	timestamp    = {2024-11-04}
}
@article{10.1109/compsac51774.2021.00173,
	title        = {A cnn sign language recognition system with single \&amp; double-handed gestures},
	author       = {Buckley, N. and Sherrett, L. and Secco, E.},
	year         = 2021,
	doi          = {10.1109/compsac51774.2021.00173},
	timestamp    = {2024-11-04}
}
@article{10.1109/access.2020.2990699,
	title        = {Deeparslr: a novel signer-independent deep learning framework for isolated arabic sign language gestures recognition},
	author       = {Aly, S. and Aly, W.},
	year         = 2020,
	journal      = {Ieee Access},
	volume       = 8,
	pages        = {83199--83212},
	doi          = {10.1109/access.2020.2990699},
	timestamp    = {2024-11-04}
}
@article{10.1109/access.2020.2993650,
	title        = {Continuous sign language recognition through cross-modal alignment of video and text embeddings in a joint-latent space},
	author       = {Papastratis, I. and Dimitropoulos, K. and Konstantinidis, D. and Daras, P.},
	year         = 2020,
	journal      = {Ieee Access},
	volume       = 8,
	pages        = {91170--91180},
	doi          = {10.1109/access.2020.2993650},
	timestamp    = {2024-11-04}
}
@article{10.13053/rcs-148-3-17,
	title        = {Data acquisition software for sign language recognition},
	author       = {Mart\'{\i}nez-Guti\'{e}rrez, M. and Rojano-C\'{a}ceres, J. and Ben\'{\i}tezâ€“Guerrero, E. and S\'{a}nchez-Barrera, H.},
	year         = 2019,
	journal      = {Research in Computing Science},
	volume       = 148,
	pages        = {205--211},
	doi          = {10.13053/rcs-148-3-17},
	issue        = 3,
	timestamp    = {2024-11-04}
}
@article{10.1002/cpe.7653,
	title        = {A review on computational methods based automated sign language recognition system for hearing and speech impaired community},
	author       = {Robert, E. and Hemanth, D.},
	year         = 2023,
	journal      = {Concurrency and Computation Practice and Experience},
	volume       = 35,
	doi          = {10.1002/cpe.7653},
	issue        = 9,
	timestamp    = {2024-11-04}
}
@article{10.13053/rcs-148-6-19,
	title        = {Sign language recognition based on emg signals through a hibrid intelligent system},
	author       = {Rodr\'{\i}guez-Tapia, B. and Ochoa-Zezzatti, A. and Marrufo, \'{A}. and Arballo, N. and Carlos, P.},
	year         = 2019,
	journal      = {Research in Computing Science},
	volume       = 148,
	pages        = {253--262},
	doi          = {10.13053/rcs-148-6-19},
	issue        = 6,
	timestamp    = {2024-11-04}
}
@article{10.1007/978-3-030-66096-3_13,
	title        = {Slrtp 2020: the sign language recognition, translation \&amp; production workshop},
	author       = {Camg\"{o}z, N. and Varol, G. and Albanie, S. and Fox, N. and Bowden, R. and Zisserman, A. and Cormier, K.},
	year         = 2020,
	pages        = {179--185},
	doi          = {10.1007/978-3-030-66096-3_13},
	timestamp    = {2024-11-04}
}
@article{10.32604/cmc.2022.025953,
	title        = {Intelligent sign language recognition system for e-learning context},
	author       = {Hussain, M. and Shaoor, A. and Alsuhibany, S. and Ghadi, Y. and Shloul, T. and Jalal, A. and Park, J.},
	year         = 2022,
	journal      = {Computers Materials \& Continua},
	volume       = 72,
	pages        = {5327--5343},
	doi          = {10.32604/cmc.2022.025953},
	issue        = 3,
	timestamp    = {2024-11-04}
}
@article{10.48550/arxiv.2010.11929,
	title        = {An image is worth 16x16 words: transformers for image recognition at scale},
	author       = {Dosovitskiy, A.},
	year         = 2020,
	doi          = {10.48550/arxiv.2010.11929},
	timestamp    = {2024-11-04}
}
@article{10.1145/3308561.3353774,
	title        = {Sign language recognition, generation, and translation},
	author       = {Bragg, D. and Koller, O. and Bellard, M. and Berke, L. and Boudreault, P. and Braffort, A. and Caselli, N. and Huenerfauth, M. and Kacorri, H. and Verhoef, T. and Vogler, C. and Morris, M.},
	year         = 2019,
	pages        = {16--31},
	doi          = {10.1145/3308561.3353774},
	timestamp    = {2024-11-04}
}
@article{vanmeerbergen2000simultane,
	title        = {Simultane constructies in de Vlaamse Gebarentaal},
	author       = {Vanmeerbergen, Myriam},
	year         = 2000,
	journal      = {Handelingen-Koninklijke Zuid-Nederlandse maatschappij voor taal-en letterkunde en geschiedenis},
	publisher    = {Koninklijke Zuid-Nederlandse Maatschappij voor Taal-en Letterkunde en~\ldots{}},
	volume       = 54,
	url          = {https://openjournals.ugent.be/kzm/article/id/72219/download/pdf/},
	timestamp    = {2024-11-05}
}
@phdthesis{469340,
	title        = {Fonologie van de Vlaamse Gebarentaal: distinctiviteit en iconiciteit},
	author       = {Demey, Eline},
	year         = 2005,
	publisher    = {Universiteit Gent. Faculteit Letteren en Wijsbegeerte},
	pages        = 550,
	url          = {http://lib.ugent.be/fulltxt/RUG01/000/938/845/RUG01-000938845_2010_0001_AC.pdf},
	abstract     = {De doelstelling van dit proefschrift is een eerste uitgebreide beschrijving te geven van de fonologische vormelementen en structuren in de Vlaamse Gebarentaal (VGT) en na te gaan wat daarbij de plaats van iconiciteit binnen (of buiten?) een fonologisch model kan zijn. De focus ligt op het manuele gedeelte van gebaren, d.w.z. de vier parameters handvorm, ori\"{e}ntatie van de hand, articulatieplaats en beweging van het gebaar. De basis voor de fonologische beschrijving is een gedetailleerde fonetische transcriptie van een 2400-tal ge\"{\i}soleerde VGT-gebaren (gebaren in citeervorm), getranscribeerd met een vereenvoudigde versie van SignPhon (Crasborn et al. 1997). De fonologische analyse van die gebaren gebeurt aan de hand van een model dat ontwikkeld is voor de Nederlandse Gebarentaal (NGT), met name het dependentiemodel van Van der Kooij (2002).},
	keywords     = {transcriptie,fonologie,iconiciteit,dependentiemodel,Vlaamse Gebarentaal (VGT)},
	language     = {dut},
	school       = {Ghent University},
	timestamp    = {2024-11-05}
}
@article{10.52756/ijerr.2023.v34spl.004,
	title        = {Machine learning-based gesture recognition for communication with the deaf and dumb},
	author       = {Yavanamandha, P. and Keerthana, B. and Jahnavi, P. and Rao, K. V. and Kumar, C. R.},
	year         = 2023,
	journal      = {International Journal of Experimental Research and Review},
	volume       = 34,
	pages        = {26--35},
	doi          = {10.52756/ijerr.2023.v34spl.004},
	issue        = {Special Vo},
	timestamp    = {2024-11-15}
}
@article{10.17485/ijst/v16i45.2583,
	title        = {Transforming sign language into text and speech through deep learning technologies},
	author       = {Duraisamy, P. and Abinayasrijanani, A. and Candida, M. A. and Babu, P. D.},
	year         = 2023,
	journal      = {Indian Journal of Science and Technology},
	volume       = 16,
	pages        = {4177--4185},
	doi          = {10.17485/ijst/v16i45.2583},
	issue        = 45,
	timestamp    = {2024-11-15}
}
@inproceedings{9491631,
	title        = {Deep CNN Model based on VGG16 for Breast Cancer Classification},
	author       = {Albashish, Dheeb and Al-Sayyed, Rizik and Abdullah, Azizi and Ryalat, Mohammad Hashem and Ahmad Almansour, Nedaa},
	year         = 2021,
	booktitle    = {2021 International Conference on Information Technology (ICIT)},
	pages        = {805--810},
	doi          = {10.1109/ICIT52682.2021.9491631},
	keywords     = {Deep learning;Adaptation models;Visualization;Histopathology;Computational modeling;Benchmark testing;Feature extraction;Deep learning;VGG16;BreaKHis histopathology dataset;feature extraction;pre-trained model},
	timestamp    = {2024-11-15}
}
@incollection{torrey2010transfer,
	title        = {Transfer learning},
	author       = {Torrey, Lisa and Shavlik, Jude},
	year         = 2010,
	booktitle    = {Handbook of research on machine learning applications and trends: algorithms, methods, and techniques},
	publisher    = {IGI global},
	pages        = {242--264},
	timestamp    = {2024-11-15}
}
@article{Abu-Jamie2022-ABUCOS-2,
	title        = {Classification of Sign-Language Using Vgg16},
	author       = {Tanseem N. Abu-Jamie and Samy S. Abu-Naser},
	year         = 2022,
	journal      = {International Journal of Academic Engineering Research (IJAER)},
	volume       = 6,
	number       = 6,
	pages        = {36--46},
	timestamp    = {2024-11-15}
}
@article{Wang2022,
	title        = {Improved 3D-ResNet sign language recognition algorithm with enhanced hand features},
	author       = {Shiqi Wang and Kankan Wang and Tingping Yang and Yiming Li and Di Fan},
	year         = 2022,
	journal      = {Scientific Reports},
	volume       = 12,
	number       = 1,
	pages        = 17812,
	doi          = {10.1038/s41598-022-21636-z},
	issn         = {2045-2322},
	url          = {https://doi.org/10.1038/s41598-022-21636-z},
	note         = {Published: 2022/10/24},
	abstract     = {In sign language video, the hand region is small, the resolution is low, the motion speed is fast, and there are cross occlusion and blur phenomena, which have a great impact on sign language recognition rate and speed, and are important factors restricting sign language recognition performance. To solve these problems, this paper proposes an improved 3D-ResNet sign language recognition algorithm with enhanced hand features, aiming to highlight the features of both hands, solve the problem of missing more effective information when relying only on global features, and improve the accuracy of sign language recognition. The proposed method has two improvements. Firstly, the algorithm detects the left and right hand regions based on the improved EfficientDet network, uses the improved Bi-FPN module and dual channel and spatial attention module are used to enhance the detection ability of the network for small targets like hand. Secondly, the improved residual module is used to improve the 3D-ResNet18 network to extract sign language features. The global, the left-hand and the right-hand image sequences are divided into three branches for feature extraction and fusion, so as to strengthen the attention to hand features, strengthen the representation ability of sign language features, and achieve the purpose of improving the accuracy of sign language recognition. In order to verify the performance of this algorithm, a series of experiments are carried out on CSL dataset. For example, in the experiments of hand detection algorithm and sign language recognition algorithm, the performance indicators such as Top-N, mAP, FLOPs and Parm are applied to find the optimal algorithm framework. The experimental results show that the Top1 recognition accuracy of this algorithm reaches 91.12\%, which is more than 10\% higher than that of C3D, P3D and 3D-ResNet basic networks. From the performance indicators of Top-N, mAP, FLOPs, Parm and so on, the performance of the algorithm in this paper is better than several algorithms in recent three years, such as I3D+BLSTM, B3D ResNet, AM-ResC3D+RCNN and so on. The results show that the hand detection network with enhanced hand features and three-dimensional convolutional neural network proposed in this paper can achieve higher accuracy of sign language recognition.},
	timestamp    = {2024-11-15}
}
@misc{Coster2023,
	title        = {Towards the extraction of robust sign embeddings for low resource sign language recognition},
	author       = {Coster, Mathieu and Rushe, Ellen and Holmes, Ruth and Ventresque, Anthony and Dambre, J.},
	year         = 2023,
	month        = {06},
	doi          = {10.48550/arXiv.2306.17558},
	timestamp    = {2024-11-15}
}
@misc{Corpus_VGT,
	title        = {Het Corpus VGT. Een digitaal open access corpus van videos and annotaties van Vlaamse Gebarentaal, ontwikkeld aan de Universiteit Gent ism KU Leuven. <www.corpusvgt.be>},
	author       = {Van Herreweghe, Mieke and Vermeerbergen, Myriam and Demey, Eline and De Durpel, Hannes and Nyffels, Hilde and Verstraete, Sam},
	year         = 2015,
	url          = {http://www.corpusvgt.ugent.be/},
	abstract     = {
		Het Corpus VGT is een verzameling van video's in Vlaamse Gebarentaal. We verzamelden in totaal meer dan 5 TB of 140 uren video. 120 dove mensen werkten mee aan het Corpus VGT als informanten. Bij het selecteren van de informanten werd rekening gehouden met leeftijd, regio en gender. Per twee gaven we hen een reeks thema's om over te praten: vertellen van een verhaal, maken van afspraken, discussi\"{e}ren over een thema, vertellen over hun schooltijd enz. Deze conversaties namen we op video op en we monteerden ze per opdracht. De gesprekken in Vlaamse Gebarentaal annoteerden we vervolgens door ze te glossen.

		Het Corpus VGT is gemaakt om onderzoek naar Vlaamse Gebarentaal te doen. Omdat er in andere landen ook al gebarentaalcorpora zijn samengesteld, kan men ook vergelijkend onderzoek tussen Vlaamse Gebarentaal en andere gebarentalen doen. Daarnaast kunnen docenten het corpus gebruiken in hun lessen Vlaamse Gebarentaal. Het Corpus VGT is ook een middel om Vlaamse Gebarentaal en aspecten van de Vlaamse Dovencultuur te documenteren en te bewaren.
	},
	keywords     = {Vlaamse Gebarentaal,Corpuslingu\"{\i}stiek},
	language     = {dut},
	timestamp    = {2024-11-15}
}
@misc{VGT_Signbank,
	url          = {https://signbank.vlaamsegebarentaal.be/accounts/login/?next=/datasets/available},
	timestamp    = {2024-11-15}
}
@misc{Over_het_Corpus_VGT,
	url          = {https://www.corpusvgt.be/},
	timestamp    = {2024-11-15}
}

@Inbook{Vandeghinste2024,
author="Vandeghinste, Vincent
and De Sisto, Mirella
and G{\'o}mez, Santiago Egea
and De Coster, Mathieu",
editor="Way, Andy
and Leeson, Lorraine
and Shterionov, Dimitar",
title="Challenges with Sign Language Datasets",
bookTitle="Sign Language Machine Translation",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="117--139",
abstract="Sign Languages are the primary means of communication more than half a million people in Europe alone. However, the development of sign language recognition and translation tools is slowed down by a series of obstacles concerning resource scarcity and, when data is available, in standardisation issues in the available data.",
isbn="978-3-031-47362-3",
doi="10.1007/978-3-031-47362-3_5",
url="https://doi.org/10.1007/978-3-031-47362-3_5"
}
